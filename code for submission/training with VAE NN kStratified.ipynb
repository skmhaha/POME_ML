{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfbf1f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 01:52:15.139381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed=42\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581991ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_ods_reader import read_ods\n",
    "\n",
    "df = read_ods('Biogas data.ods', 'plant1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4e6818",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = df._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9b29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = num.iloc[:, :]\n",
    "\n",
    "y = num.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7d86bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_vae = StandardScaler()\n",
    "\n",
    "x_full_scaled = scaler_vae.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c4a5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.38240012 -0.90798538 -0.90900974  1.45070271  0.31622777 -0.23325717]\n",
      " [-0.31992351  0.51000078  0.51131798  1.89299012  0.31622777 -0.25700507]\n",
      " [-1.26434716 -0.84366537 -0.84321799  1.89299012  0.31622777 -0.15937481]\n",
      " [ 0.27771958  0.35176828  0.35264376  0.87572907 -1.26491106  0.29447399]\n",
      " [ 0.24082803 -0.54820918 -0.54909018 -0.4953619  -0.47434165  0.81956649]\n",
      " [ 0.5212038   0.30564283  0.30620253  0.07961173 -0.47434165  3.0993651 ]\n",
      " [ 0.61712183  0.50054329  0.49970767  0.52189914  0.31622777  3.02548274]\n",
      " [-1.21269899 -1.10845005 -1.10638498  0.43344166  0.31622777  0.72985219]\n",
      " [ 2.10016209 -1.61220308 -1.61336844 -3.41445881  0.31622777 -0.07493782]\n",
      " [ 2.68304856  2.48904564  2.48894049 -0.22998945  1.10679718 -0.32297147]\n",
      " [ 0.68352662  1.80070272  1.8000622   0.65458537  0.31622777 -0.84278666]\n",
      " [-1.02824125 -0.98227494 -0.98254169 -0.18576071  1.10679718 -0.67655135]\n",
      " [ 0.81633619  1.14967663  1.14988494 -0.45113316  1.8973666  -0.79001355]\n",
      " [-1.10940265 -0.67365974 -0.67293347 -0.62804812  0.31622777 -1.02485391]\n",
      " [ 0.68352662  2.02845767  2.02839826 -0.27421819  1.10679718 -0.72932446]\n",
      " [-0.7626221  -0.13503612 -0.13498918 -0.7165056  -1.26491106 -0.3810219 ]\n",
      " [-0.49700294 -0.09087079 -0.09241805 -0.36267568 -2.05548048 -0.39949249]\n",
      " [-0.51175956 -0.26267691 -0.26270258 -0.36267568 -2.05548048 -0.34408072]\n",
      " [ 0.79420126  0.49252661  0.49196746 -0.36267568 -1.26491106 -0.44962695]\n",
      " [-0.77000041 -0.54935664 -0.54909018 -0.27421819 -0.47434165 -0.30186222]\n",
      " [ 0.01210043  0.06786236  0.06625616  0.12384047 -0.47434165  0.2997513 ]\n",
      " [-1.10202434 -1.19802664 -1.19926745  0.07961173 -0.47434165 -0.55253452]\n",
      " [ 0.10801845 -0.3175892  -0.31688401 -0.58381938  1.10679718 -0.32824878]\n",
      " [ 0.24082803 -0.12052027 -0.11950877  0.16806922  1.10679718 -0.29922357]\n",
      " [ 0.18180155 -0.34570251 -0.34397473  0.16806922  0.31622777 -0.10132438]]\n"
     ]
    }
   ],
   "source": [
    "print(x_full_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c044997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba66561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfe152c7",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b244806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 01:52:17.017309: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-31 01:52:17.017546: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-31 01:52:17.017556: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-31 01:52:17.017570: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-GM3F9HH): /proc/driver/nvidia/version does not exist\n",
      "2022-08-31 01:52:17.017737: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-31 01:52:17.018159: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-31 01:52:17.922770: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-08-31 01:52:17.941475: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 1.0067 - mean_squared_error: 1.0018\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0302 - mean_squared_error: 1.0082\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9886 - mean_squared_error: 0.9829\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9658 - mean_squared_error: 0.9527\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8484 - mean_squared_error: 0.8208\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6572 - mean_squared_error: 0.6093\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6417 - mean_squared_error: 0.5614\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5518 - mean_squared_error: 0.5045\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5082 - mean_squared_error: 0.4265\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5710 - mean_squared_error: 0.5145\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4468 - mean_squared_error: 0.4025\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5174 - mean_squared_error: 0.4931\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5454 - mean_squared_error: 0.5187\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4314 - mean_squared_error: 0.3993\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4470 - mean_squared_error: 0.4154\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4108 - mean_squared_error: 0.3715\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3955 - mean_squared_error: 0.3527\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3824 - mean_squared_error: 0.3365\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3687 - mean_squared_error: 0.3307\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3420 - mean_squared_error: 0.3115\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3277 - mean_squared_error: 0.2895\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3214 - mean_squared_error: 0.2800\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3383 - mean_squared_error: 0.3016\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2947 - mean_squared_error: 0.2599\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2947 - mean_squared_error: 0.2629\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3020 - mean_squared_error: 0.2775\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3147 - mean_squared_error: 0.2823\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3185 - mean_squared_error: 0.2880\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3405 - mean_squared_error: 0.3112\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2695 - mean_squared_error: 0.2348\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2674 - mean_squared_error: 0.2336\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2918 - mean_squared_error: 0.2606\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2575 - mean_squared_error: 0.2226\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2572 - mean_squared_error: 0.2238\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3196 - mean_squared_error: 0.2805\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2527 - mean_squared_error: 0.2197\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2993 - mean_squared_error: 0.2686\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3086 - mean_squared_error: 0.2777\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2759 - mean_squared_error: 0.2464\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2229 - mean_squared_error: 0.1909\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2330 - mean_squared_error: 0.1971\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2419 - mean_squared_error: 0.2088\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2320 - mean_squared_error: 0.1920\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1976 - mean_squared_error: 0.1681\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2217 - mean_squared_error: 0.1900\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2238 - mean_squared_error: 0.2010\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2211 - mean_squared_error: 0.1895\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3352 - mean_squared_error: 0.3004\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1642 - mean_squared_error: 0.1394\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2777 - mean_squared_error: 0.2520\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2289 - mean_squared_error: 0.1931\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1922 - mean_squared_error: 0.1651\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2496 - mean_squared_error: 0.2203\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2464 - mean_squared_error: 0.2192\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2015 - mean_squared_error: 0.1753\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2321 - mean_squared_error: 0.2043\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1819 - mean_squared_error: 0.1413\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1890 - mean_squared_error: 0.1506\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1758 - mean_squared_error: 0.1462\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1898 - mean_squared_error: 0.1533\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2507 - mean_squared_error: 0.2195\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1839 - mean_squared_error: 0.1551\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1848 - mean_squared_error: 0.1581\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2507 - mean_squared_error: 0.2223\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1801 - mean_squared_error: 0.1573\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1676 - mean_squared_error: 0.1379\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1384 - mean_squared_error: 0.1110\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1481 - mean_squared_error: 0.1141\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1701 - mean_squared_error: 0.1385\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1542 - mean_squared_error: 0.1212\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1423 - mean_squared_error: 0.1124\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1516 - mean_squared_error: 0.1192\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1524 - mean_squared_error: 0.1202\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1442 - mean_squared_error: 0.1183\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1314 - mean_squared_error: 0.1054\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1668 - mean_squared_error: 0.1421\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1325 - mean_squared_error: 0.1028\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1459 - mean_squared_error: 0.1182\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1648 - mean_squared_error: 0.1364\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1415 - mean_squared_error: 0.1189\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1450 - mean_squared_error: 0.1156\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1391 - mean_squared_error: 0.1121\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1641 - mean_squared_error: 0.1390\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1542 - mean_squared_error: 0.1275\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1426 - mean_squared_error: 0.1164\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1302 - mean_squared_error: 0.1019\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1627 - mean_squared_error: 0.1383\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1227 - mean_squared_error: 0.0967\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1253 - mean_squared_error: 0.0997\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1342 - mean_squared_error: 0.1035\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1387 - mean_squared_error: 0.1091\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1216 - mean_squared_error: 0.0922\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1514 - mean_squared_error: 0.1216\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1524 - mean_squared_error: 0.1182\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1239 - mean_squared_error: 0.0944\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1387 - mean_squared_error: 0.1115\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1174 - mean_squared_error: 0.0934\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1685 - mean_squared_error: 0.1429\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1615 - mean_squared_error: 0.1300\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1419 - mean_squared_error: 0.1128\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1516 - mean_squared_error: 0.1184\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1359 - mean_squared_error: 0.1051\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1271 - mean_squared_error: 0.0986\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1303 - mean_squared_error: 0.1008\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1305 - mean_squared_error: 0.1017\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1718 - mean_squared_error: 0.1474\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1287 - mean_squared_error: 0.0978\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1556 - mean_squared_error: 0.1282\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1351 - mean_squared_error: 0.0994\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1222 - mean_squared_error: 0.0911\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1204 - mean_squared_error: 0.0914\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1308 - mean_squared_error: 0.1023\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1710 - mean_squared_error: 0.1501\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1549 - mean_squared_error: 0.1329\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1240 - mean_squared_error: 0.0988\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1166 - mean_squared_error: 0.0922\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1266 - mean_squared_error: 0.0967\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1090 - mean_squared_error: 0.0805\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1391 - mean_squared_error: 0.1060\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1296 - mean_squared_error: 0.0964\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1491 - mean_squared_error: 0.1134\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1283 - mean_squared_error: 0.0947\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1665 - mean_squared_error: 0.1342\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1494 - mean_squared_error: 0.1199\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1376 - mean_squared_error: 0.1105\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1409 - mean_squared_error: 0.1130\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1200 - mean_squared_error: 0.0906\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1833 - mean_squared_error: 0.1510\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0998 - mean_squared_error: 0.0687\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1182 - mean_squared_error: 0.0875\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1198 - mean_squared_error: 0.0927\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1070 - mean_squared_error: 0.0801\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1165 - mean_squared_error: 0.0909\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1074 - mean_squared_error: 0.0797\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1151 - mean_squared_error: 0.0879\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1072 - mean_squared_error: 0.0786\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0958 - mean_squared_error: 0.0679\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0972 - mean_squared_error: 0.0717\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0884 - mean_squared_error: 0.0627\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1003 - mean_squared_error: 0.0746\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1006 - mean_squared_error: 0.0747\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1136 - mean_squared_error: 0.0840\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0960 - mean_squared_error: 0.0694\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1014 - mean_squared_error: 0.0755\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1053 - mean_squared_error: 0.0783\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0943 - mean_squared_error: 0.0673\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1309 - mean_squared_error: 0.1090\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0997 - mean_squared_error: 0.0752\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0897 - mean_squared_error: 0.0610\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0970 - mean_squared_error: 0.0707\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0860 - mean_squared_error: 0.0622\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1285 - mean_squared_error: 0.1026\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1062 - mean_squared_error: 0.0813\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0927 - mean_squared_error: 0.0682\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1115 - mean_squared_error: 0.0870\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0999 - mean_squared_error: 0.0727\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1147 - mean_squared_error: 0.0829\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1336 - mean_squared_error: 0.1029\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1074 - mean_squared_error: 0.0752\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1266 - mean_squared_error: 0.0996\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1128 - mean_squared_error: 0.0850\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1055 - mean_squared_error: 0.0792\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1003 - mean_squared_error: 0.0742\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1033 - mean_squared_error: 0.0769\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0911 - mean_squared_error: 0.0624\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1022 - mean_squared_error: 0.0769\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1238 - mean_squared_error: 0.0948\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1035 - mean_squared_error: 0.0778\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1178 - mean_squared_error: 0.0930\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0923 - mean_squared_error: 0.0639\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1108 - mean_squared_error: 0.0788\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1219 - mean_squared_error: 0.0935\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1152 - mean_squared_error: 0.0918\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1035 - mean_squared_error: 0.0719\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1246 - mean_squared_error: 0.0947\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1152 - mean_squared_error: 0.0899\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0897 - mean_squared_error: 0.0605\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1037 - mean_squared_error: 0.0738\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0972 - mean_squared_error: 0.0676\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0933 - mean_squared_error: 0.0631\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1140 - mean_squared_error: 0.0821\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1279 - mean_squared_error: 0.0966\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1207 - mean_squared_error: 0.0930\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1035 - mean_squared_error: 0.0746\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0927 - mean_squared_error: 0.0638\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0985 - mean_squared_error: 0.0725\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0933 - mean_squared_error: 0.0666\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1060 - mean_squared_error: 0.0796\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0766 - mean_squared_error: 0.0504\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0984 - mean_squared_error: 0.0739\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1356 - mean_squared_error: 0.1128\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1067 - mean_squared_error: 0.0815\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0957 - mean_squared_error: 0.0689\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1233 - mean_squared_error: 0.0956\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0983 - mean_squared_error: 0.0718\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1504 - mean_squared_error: 0.1191\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1539 - mean_squared_error: 0.1230\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1215 - mean_squared_error: 0.0941\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0979 - mean_squared_error: 0.0685\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1053 - mean_squared_error: 0.0771\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1222 - mean_squared_error: 0.0912\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1273 - mean_squared_error: 0.1031\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1207 - mean_squared_error: 0.0937\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0785 - mean_squared_error: 0.0473\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0952 - mean_squared_error: 0.0660\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0803 - mean_squared_error: 0.0475\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1190 - mean_squared_error: 0.0811\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0880 - mean_squared_error: 0.0562\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0920 - mean_squared_error: 0.0635\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1022 - mean_squared_error: 0.0734\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1137 - mean_squared_error: 0.0856\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1566 - mean_squared_error: 0.1291\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1527 - mean_squared_error: 0.1211\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1628 - mean_squared_error: 0.1291\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1182 - mean_squared_error: 0.0897\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1079 - mean_squared_error: 0.0787\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1031 - mean_squared_error: 0.0773\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1042 - mean_squared_error: 0.0723\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1054 - mean_squared_error: 0.0788\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1016 - mean_squared_error: 0.0727\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1333 - mean_squared_error: 0.1052\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1383 - mean_squared_error: 0.1101\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1237 - mean_squared_error: 0.0936\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0888 - mean_squared_error: 0.0595\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1520 - mean_squared_error: 0.1246\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1240 - mean_squared_error: 0.0898\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1134 - mean_squared_error: 0.0819\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1186 - mean_squared_error: 0.0843\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1071 - mean_squared_error: 0.0772\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1120 - mean_squared_error: 0.0777\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0982 - mean_squared_error: 0.0665\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1014 - mean_squared_error: 0.0768\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1325 - mean_squared_error: 0.1015\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0892 - mean_squared_error: 0.0620\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0983 - mean_squared_error: 0.0716\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1120 - mean_squared_error: 0.0835\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1044 - mean_squared_error: 0.0778\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1106 - mean_squared_error: 0.0752\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0941 - mean_squared_error: 0.0633\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1046 - mean_squared_error: 0.0712\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1010 - mean_squared_error: 0.0736\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0847 - mean_squared_error: 0.0550\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1088 - mean_squared_error: 0.0785\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0824 - mean_squared_error: 0.0517\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0812 - mean_squared_error: 0.0502\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0849 - mean_squared_error: 0.0551\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0962 - mean_squared_error: 0.0696\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0677 - mean_squared_error: 0.0392\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0830 - mean_squared_error: 0.0540\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0854 - mean_squared_error: 0.0562\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0937 - mean_squared_error: 0.0619\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0724 - mean_squared_error: 0.0437\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0905 - mean_squared_error: 0.0622\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1241 - mean_squared_error: 0.0966\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0843 - mean_squared_error: 0.0595\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1116 - mean_squared_error: 0.0877\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0902 - mean_squared_error: 0.0654\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0853 - mean_squared_error: 0.0600\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0863 - mean_squared_error: 0.0617\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0943 - mean_squared_error: 0.0663\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1081 - mean_squared_error: 0.0802\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0989 - mean_squared_error: 0.0708\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1339 - mean_squared_error: 0.1102\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0783 - mean_squared_error: 0.0522\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0813 - mean_squared_error: 0.0539\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0783 - mean_squared_error: 0.0507\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0813 - mean_squared_error: 0.0548\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1194 - mean_squared_error: 0.0980\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1050 - mean_squared_error: 0.0824\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0665 - mean_squared_error: 0.0416\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0982 - mean_squared_error: 0.0716\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1061 - mean_squared_error: 0.0790\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1304 - mean_squared_error: 0.1052\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1051 - mean_squared_error: 0.0781\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1164 - mean_squared_error: 0.0881\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1102 - mean_squared_error: 0.0824\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0990 - mean_squared_error: 0.0694\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0888 - mean_squared_error: 0.0560\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0929 - mean_squared_error: 0.0543\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1117 - mean_squared_error: 0.0751\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1157 - mean_squared_error: 0.0812\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0855 - mean_squared_error: 0.0521\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0856 - mean_squared_error: 0.0507\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1014 - mean_squared_error: 0.0707\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0756 - mean_squared_error: 0.0436\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0944 - mean_squared_error: 0.0651\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1160 - mean_squared_error: 0.0881\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0998 - mean_squared_error: 0.0656\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1282 - mean_squared_error: 0.1015\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0838 - mean_squared_error: 0.0524\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0765 - mean_squared_error: 0.0526\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0991 - mean_squared_error: 0.0712\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0889 - mean_squared_error: 0.0598\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1159 - mean_squared_error: 0.0866\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1048 - mean_squared_error: 0.0706\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1178 - mean_squared_error: 0.0937\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0912 - mean_squared_error: 0.0610\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0781 - mean_squared_error: 0.0506\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0781 - mean_squared_error: 0.0544\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0851 - mean_squared_error: 0.0641\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1002 - mean_squared_error: 0.0759\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0749 - mean_squared_error: 0.0526\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0850 - mean_squared_error: 0.0611\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1196 - mean_squared_error: 0.0910\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0835 - mean_squared_error: 0.0546\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1423 - mean_squared_error: 0.1085\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0762 - mean_squared_error: 0.0474\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0893 - mean_squared_error: 0.0602\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1255 - mean_squared_error: 0.0969\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1053 - mean_squared_error: 0.0774\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0985 - mean_squared_error: 0.0705\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0816 - mean_squared_error: 0.0546\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1203 - mean_squared_error: 0.0924\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1003 - mean_squared_error: 0.0723\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0671 - mean_squared_error: 0.0390\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0887 - mean_squared_error: 0.0578\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0848 - mean_squared_error: 0.0506\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0877 - mean_squared_error: 0.0590\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1073 - mean_squared_error: 0.0774\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0933 - mean_squared_error: 0.0685\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1076 - mean_squared_error: 0.0791\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0741 - mean_squared_error: 0.0470\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1831 - mean_squared_error: 0.1554\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0933 - mean_squared_error: 0.0696\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0914 - mean_squared_error: 0.0694\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1386 - mean_squared_error: 0.1170\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1603 - mean_squared_error: 0.1418\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1339 - mean_squared_error: 0.1111\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0918 - mean_squared_error: 0.0707\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1067 - mean_squared_error: 0.0823\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1098 - mean_squared_error: 0.0853\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1273 - mean_squared_error: 0.0980\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1140 - mean_squared_error: 0.0803\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1086 - mean_squared_error: 0.0769\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0815 - mean_squared_error: 0.0494\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0863 - mean_squared_error: 0.0528\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0818 - mean_squared_error: 0.0431\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1020 - mean_squared_error: 0.0676\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1096 - mean_squared_error: 0.0722\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0871 - mean_squared_error: 0.0538\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0972 - mean_squared_error: 0.0647\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0886 - mean_squared_error: 0.0578\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0770 - mean_squared_error: 0.0477\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0772 - mean_squared_error: 0.0443\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0861 - mean_squared_error: 0.0562\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0840 - mean_squared_error: 0.0568\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0635 - mean_squared_error: 0.0373\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0798 - mean_squared_error: 0.0506\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0790 - mean_squared_error: 0.0481\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1129 - mean_squared_error: 0.0897\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0947 - mean_squared_error: 0.0659\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0652 - mean_squared_error: 0.0386\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0921 - mean_squared_error: 0.0632\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0834 - mean_squared_error: 0.0575\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0867 - mean_squared_error: 0.0584\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0681 - mean_squared_error: 0.0418\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0631 - mean_squared_error: 0.0398\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0698 - mean_squared_error: 0.0465\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0659 - mean_squared_error: 0.0387\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1509 - mean_squared_error: 0.1256\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0638 - mean_squared_error: 0.0416\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0723 - mean_squared_error: 0.0499\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0715 - mean_squared_error: 0.0459\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0839 - mean_squared_error: 0.0563\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0757 - mean_squared_error: 0.0519\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0702 - mean_squared_error: 0.0421\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0666 - mean_squared_error: 0.0429\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0710 - mean_squared_error: 0.0471\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0700 - mean_squared_error: 0.0436\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0704 - mean_squared_error: 0.0484\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0687 - mean_squared_error: 0.0467\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0740 - mean_squared_error: 0.0512\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0954 - mean_squared_error: 0.0754\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0683 - mean_squared_error: 0.0498\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0741 - mean_squared_error: 0.0510\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0675 - mean_squared_error: 0.0452\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0735 - mean_squared_error: 0.0516\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0882 - mean_squared_error: 0.0664\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0902 - mean_squared_error: 0.0700\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0646 - mean_squared_error: 0.0409\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0765 - mean_squared_error: 0.0556\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0770 - mean_squared_error: 0.0562\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1224 - mean_squared_error: 0.1022\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0671 - mean_squared_error: 0.0450\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0758 - mean_squared_error: 0.0514\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1096 - mean_squared_error: 0.0817\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1216 - mean_squared_error: 0.0932\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0920 - mean_squared_error: 0.0651\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1053 - mean_squared_error: 0.0768\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0587 - mean_squared_error: 0.0323\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0768 - mean_squared_error: 0.0450\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0956 - mean_squared_error: 0.0678\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0805 - mean_squared_error: 0.0528\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0786 - mean_squared_error: 0.0461\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0742 - mean_squared_error: 0.0437\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0726 - mean_squared_error: 0.0424\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0657 - mean_squared_error: 0.0374\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0845 - mean_squared_error: 0.0522\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0668 - mean_squared_error: 0.0372\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0701 - mean_squared_error: 0.0402\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1027 - mean_squared_error: 0.0707\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0784 - mean_squared_error: 0.0510\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1135 - mean_squared_error: 0.0861\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0761 - mean_squared_error: 0.0465\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0609 - mean_squared_error: 0.0315\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0884 - mean_squared_error: 0.0635\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0724 - mean_squared_error: 0.0475\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0700 - mean_squared_error: 0.0404\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0977 - mean_squared_error: 0.0708\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0602 - mean_squared_error: 0.0352\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0870 - mean_squared_error: 0.0581\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0706 - mean_squared_error: 0.0442\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0912 - mean_squared_error: 0.0608\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0662 - mean_squared_error: 0.0402\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0603 - mean_squared_error: 0.0326\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0730 - mean_squared_error: 0.0449\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0594 - mean_squared_error: 0.0310\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0750 - mean_squared_error: 0.0473\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0662 - mean_squared_error: 0.0399\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0998 - mean_squared_error: 0.0727\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1022 - mean_squared_error: 0.0744\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1170 - mean_squared_error: 0.0914\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0742 - mean_squared_error: 0.0456\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0889 - mean_squared_error: 0.0602\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0882 - mean_squared_error: 0.0584\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0750 - mean_squared_error: 0.0419\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1369 - mean_squared_error: 0.1061\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0891 - mean_squared_error: 0.0569\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0933 - mean_squared_error: 0.0610\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0854 - mean_squared_error: 0.0508\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1261 - mean_squared_error: 0.0946\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0738 - mean_squared_error: 0.0426\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0783 - mean_squared_error: 0.0498\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0883 - mean_squared_error: 0.0602\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1531 - mean_squared_error: 0.1220\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0680 - mean_squared_error: 0.0332\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0985 - mean_squared_error: 0.0644\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1038 - mean_squared_error: 0.0728\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1245 - mean_squared_error: 0.0970\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1323 - mean_squared_error: 0.0964\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0965 - mean_squared_error: 0.0665\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1054 - mean_squared_error: 0.0782\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1035 - mean_squared_error: 0.0749\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0972 - mean_squared_error: 0.0587\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0791 - mean_squared_error: 0.0459\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0902 - mean_squared_error: 0.0511\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1164 - mean_squared_error: 0.0827\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0731 - mean_squared_error: 0.0429\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0771 - mean_squared_error: 0.0446\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0720 - mean_squared_error: 0.0423\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0733 - mean_squared_error: 0.0377\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0925 - mean_squared_error: 0.0578\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0836 - mean_squared_error: 0.0515\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0710 - mean_squared_error: 0.0409\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0999 - mean_squared_error: 0.0666\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0666 - mean_squared_error: 0.0427\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1153 - mean_squared_error: 0.0829\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0845 - mean_squared_error: 0.0565\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0676 - mean_squared_error: 0.0403\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0782 - mean_squared_error: 0.0483\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1269 - mean_squared_error: 0.0997\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0739 - mean_squared_error: 0.0460\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0898 - mean_squared_error: 0.0594\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0950 - mean_squared_error: 0.0631\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0685 - mean_squared_error: 0.0424\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0849 - mean_squared_error: 0.0563\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0664 - mean_squared_error: 0.0416\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0666 - mean_squared_error: 0.0436\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0955 - mean_squared_error: 0.0698\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0541 - mean_squared_error: 0.0273\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0702 - mean_squared_error: 0.0408\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0754 - mean_squared_error: 0.0467\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0689 - mean_squared_error: 0.0412\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0820 - mean_squared_error: 0.0552\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0685 - mean_squared_error: 0.0424\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0704 - mean_squared_error: 0.0438\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0701 - mean_squared_error: 0.0454\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0622 - mean_squared_error: 0.0375\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0582 - mean_squared_error: 0.0372\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0718 - mean_squared_error: 0.0463\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0731 - mean_squared_error: 0.0503\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0640 - mean_squared_error: 0.0399\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0486 - mean_squared_error: 0.0271\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0799 - mean_squared_error: 0.0573\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0665 - mean_squared_error: 0.0404\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0579 - mean_squared_error: 0.0371\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0469 - mean_squared_error: 0.0280\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1207 - mean_squared_error: 0.0966\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0652 - mean_squared_error: 0.0415\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0721 - mean_squared_error: 0.0463\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0928 - mean_squared_error: 0.0609\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0880 - mean_squared_error: 0.0642\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0579 - mean_squared_error: 0.0324\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0722 - mean_squared_error: 0.0501\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0687 - mean_squared_error: 0.0456\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0616 - mean_squared_error: 0.0415\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0539 - mean_squared_error: 0.0339\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0676 - mean_squared_error: 0.0484\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0561 - mean_squared_error: 0.0355\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0560 - mean_squared_error: 0.0356\n"
     ]
    }
   ],
   "source": [
    "vae_mft = keras.models.load_model('vae.tf')\n",
    "history = vae_mft.fit(x_full_scaled, x_full_scaled, epochs=500)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0103228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import matplotlib.pyplot as plt\\n\\nplt.figure(figsize=(20,5))\\nplt.plot(x_full_scaled.flatten(), label='x real data')\\nplt.plot(x_simulated.flatten(), label='x simulated data')\\nplt.legend(loc='upper left')\\nplt.show()\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = x_full_scaled.shape[:][1]\n",
    "\n",
    "sample_number = 250\n",
    "\n",
    "x_simulated = np.empty((sample_number,sample_size))\n",
    " \n",
    "for i in range(sample_number):\n",
    "    x_simulated[i] = vae_mft.predict(x_full_scaled[[random.randrange(x_full_scaled.shape[0])]])\n",
    "\n",
    "    \n",
    "'''import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(x_full_scaled.flatten(), label='x real data')\n",
    "plt.plot(x_simulated.flatten(), label='x simulated data')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdbbde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full = np.concatenate([x_full_scaled, x_simulated])\n",
    "x_full = scaler_vae.inverse_transform(x_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4407c464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 6)\n"
     ]
    }
   ],
   "source": [
    "print(x_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11c68c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = x_full[:,0:-1]\n",
    "y = x_full[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea634250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = np.column_stack([x_train, y_train])\n",
    "\n",
    "x = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc084b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc59ff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 6)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "088a06e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def create_folds(df, n_s=5, n_grp=None):\n",
    "    df['Fold'] = -1\n",
    "    \n",
    "    if n_grp is None:\n",
    "        skf = KFold(n_splits=n_s)\n",
    "        target = df.iloc[:,5]\n",
    "    else:\n",
    "        skf = StratifiedKFold(n_splits=n_s)\n",
    "        df['grp'] = pd.cut(df.iloc[:,5], n_grp, labels=False)\n",
    "        target = df.grp\n",
    "    \n",
    "    for fold_no, (t, v) in enumerate(skf.split(target, target)):\n",
    "        df.loc[v, 'Fold'] = fold_no\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "561f48b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x.iloc[:,5], bins=100, density=True)\n",
    "plt.xlabel('TVA (mg/L)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11e57d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skm/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = create_folds(x, n_s=4, n_grp=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcc4b1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 4, sharex=True, sharey=True, figsize=(10,4))\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.hist(df[x.Fold == i][5], bins=100, density=True, label=f'Strat-{i+1}')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Frequency')\n",
    "    if i == 2:\n",
    "        ax.set_xlabel(\"TVA (mg/L)\")\n",
    "    ax.legend(frameon=False, handlelength=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01d7829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 vs 2: KstestResult(statistic=0.12727272727272726, pvalue=0.7695107143065164)\n",
      "Fold 1 vs 3: KstestResult(statistic=0.09090909090909091, pvalue=0.978889471707582)\n",
      "Fold 1 vs 4: KstestResult(statistic=0.10909090909090909, pvalue=0.9030745921833321)\n"
     ]
    }
   ],
   "source": [
    "for fold in np.sort(x.Fold.unique())[1:]:\n",
    "    print(f'Fold 1 vs {fold+1}:', ks_2samp(x.loc[x.Fold==0, 5], x.loc[x.Fold==fold,5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa275e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "122d27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = None, None\n",
    "x1, y1 = None, None\n",
    "x2, y2 = None, None\n",
    "x3, y3 = None, None\n",
    "\n",
    "for fold in np.sort(x.Fold.unique()):\n",
    "\n",
    "    if fold == 0:\n",
    "        x0 = pd.concat([x.loc[x.Fold==1,[0,1,2,3,4]],\n",
    "                        x.loc[x.Fold==2,[0,1,2,3,4]],\n",
    "                        x.loc[x.Fold==3,[0,1,2,3,4]]])\n",
    "        y0 = pd.concat([x.loc[x.Fold==1,5],\n",
    "                        x.loc[x.Fold==2,5],\n",
    "                        x.loc[x.Fold==3,5]])\n",
    "    elif fold == 1:\n",
    "        x1 = pd.concat([x.loc[x.Fold==0,[0,1,2,3,4]],\n",
    "                        x.loc[x.Fold==2,[0,1,2,3,4]],\n",
    "                        x.loc[x.Fold==3,[0,1,2,3,4]]])\n",
    "        y1 = pd.concat([x.loc[x.Fold==0,5],\n",
    "                        x.loc[x.Fold==2,5],\n",
    "                        x.loc[x.Fold==3,5]])\n",
    "    elif fold == 2:\n",
    "        x2 = pd.concat([x.loc[x.Fold==0,[0,1,2,3,4]],\n",
    "                        x.loc[x.Fold==1,[0,1,2,3,4]],\n",
    "                        x.loc[x.Fold==3,[0,1,2,3,4]]])\n",
    "        y2 = pd.concat([x.loc[x.Fold==0,5],\n",
    "                        x.loc[x.Fold==1,5],\n",
    "                        x.loc[x.Fold==3,5]])\n",
    "    elif fold == 3:\n",
    "        x3 = pd.concat([x.loc[x.Fold==0,[0,1,2,3,4]],\n",
    "                        x.loc[x.Fold==1,[0,1,2,3,4]],\n",
    "                        x.loc[x.Fold==2,[0,1,2,3,4]]])\n",
    "        y3 = pd.concat([x.loc[x.Fold==0,5],\n",
    "                        x.loc[x.Fold==1,5],\n",
    "                        x.loc[x.Fold==2,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97f22a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4.13218446e+02, 2.88373617e+04, 7.73098913e-01, 4.71730831e+01,\n",
       "         4.77828168e+00],\n",
       "        [6.90871343e+02, 5.95089900e+04, 1.59466265e+00, 4.72184796e+01,\n",
       "         4.81707171e+00],\n",
       "        [5.80033240e+02, 3.83911964e+04, 1.02998399e+00, 4.64326478e+01,\n",
       "         4.74710568e+00],\n",
       "        [6.86411515e+02, 5.11033813e+04, 1.36418254e+00, 4.50149276e+01,\n",
       "         4.98780163e+00],\n",
       "        [9.40578995e+02, 6.63587219e+04, 1.77325721e+00, 4.55643951e+01,\n",
       "         4.90747477e+00],\n",
       "        [4.24649035e+02, 3.02015605e+04, 8.03691486e-01, 4.56353422e+01,\n",
       "         4.87607717e+00],\n",
       "        [4.76894457e+02, 3.78516988e+04, 1.01840320e+00, 4.46887595e+01,\n",
       "         4.63093545e+00],\n",
       "        [4.20747284e+02, 3.29568604e+04, 8.81892305e-01, 4.50150372e+01,\n",
       "         4.79081320e+00],\n",
       "        [8.49382692e+02, 2.70101575e+04, 7.24081047e-01, 3.91604937e+01,\n",
       "         4.79994379e+00],\n",
       "        [3.99388891e+02, 3.04924079e+04, 8.20500197e-01, 4.97315952e+01,\n",
       "         4.78663321e+00],\n",
       "        [5.42409842e+02, 4.44244908e+04, 1.19079339e+00, 5.03458820e+01,\n",
       "         4.79868353e+00],\n",
       "        [5.92115293e+02, 3.68917785e+04, 9.86598275e-01, 4.60135162e+01,\n",
       "         4.80723379e+00],\n",
       "        [4.01217169e+02, 3.07293923e+04, 8.27883414e-01, 4.98190981e+01,\n",
       "         4.78650925e+00],\n",
       "        [9.27881880e+02, 6.60993056e+04, 1.76614414e+00, 4.55415253e+01,\n",
       "         4.90556014e+00],\n",
       "        [6.04488188e+02, 3.70287013e+04, 9.90057362e-01, 4.57784811e+01,\n",
       "         4.87107032e+00],\n",
       "        [6.83767750e+02, 5.89138510e+04, 1.57753818e+00, 4.73820551e+01,\n",
       "         4.81383887e+00],\n",
       "        [6.26825747e+02, 4.37778333e+04, 1.17493237e+00, 4.79660534e+01,\n",
       "         4.59762292e+00],\n",
       "        [3.93668216e+02, 3.04395443e+04, 8.17711497e-01, 4.97684671e+01,\n",
       "         4.78942623e+00],\n",
       "        [7.08617239e+02, 5.40255178e+04, 1.43987372e+00, 4.50230852e+01,\n",
       "         4.99233885e+00],\n",
       "        [6.97167884e+02, 4.59172613e+04, 1.22263646e+00, 4.51751233e+01,\n",
       "         4.61984957e+00],\n",
       "        [4.15554126e+02, 2.89115128e+04, 7.74954340e-01, 4.70657350e+01,\n",
       "         4.77039740e+00],\n",
       "        [6.94745765e+02, 5.17690234e+04, 1.38023671e+00, 4.49850164e+01,\n",
       "         5.00134664e+00],\n",
       "        [4.22315875e+02, 3.32187113e+04, 8.88422999e-01, 4.49934715e+01,\n",
       "         4.78602957e+00],\n",
       "        [5.96104963e+02, 3.78333161e+04, 1.01050723e+00, 4.65322494e+01,\n",
       "         4.78288455e+00],\n",
       "        [6.97990342e+02, 5.35468395e+04, 1.42633212e+00, 4.50648680e+01,\n",
       "         4.98610198e+00],\n",
       "        [5.03625299e+02, 3.90514162e+04, 1.04213894e+00, 4.51190811e+01,\n",
       "         4.51794269e+00],\n",
       "        [6.35743914e+02, 4.30072892e+04, 1.15232686e+00, 4.54913512e+01,\n",
       "         4.94439127e+00],\n",
       "        [3.98700679e+02, 3.07384088e+04, 8.28462319e-01, 5.00180197e+01,\n",
       "         4.78782320e+00],\n",
       "        [9.45000000e+02, 6.40048500e+04, 1.71400000e+00, 4.54000000e+01,\n",
       "         4.90000000e+00],\n",
       "        [4.31318222e+02, 2.87885969e+04, 7.74877949e-01, 4.64457929e+01,\n",
       "         4.70360765e+00],\n",
       "        [5.96000000e+02, 3.69281600e+04, 9.89000000e-01, 4.46000000e+01,\n",
       "         4.90000000e+00],\n",
       "        [6.56471043e+02, 4.45216040e+04, 1.19241167e+00, 4.67647547e+01,\n",
       "         4.74129535e+00],\n",
       "        [6.06000000e+02, 3.66569400e+04, 9.82000000e-01, 4.63000000e+01,\n",
       "         4.80000000e+00],\n",
       "        [5.85270325e+02, 3.99330179e+04, 1.07127830e+00, 4.64390955e+01,\n",
       "         4.69782449e+00],\n",
       "        [8.56458221e+02, 2.65541767e+04, 7.12869141e-01, 3.89057473e+01,\n",
       "         4.80851845e+00],\n",
       "        [4.25990770e+02, 3.03487254e+04, 8.08156449e-01, 4.56042797e+01,\n",
       "         4.87749930e+00],\n",
       "        [4.76325830e+02, 3.77544951e+04, 1.01475847e+00, 4.48806335e+01,\n",
       "         4.61532968e+00],\n",
       "        [6.10648364e+02, 4.36823448e+04, 1.16989410e+00, 4.78772798e+01,\n",
       "         4.62718590e+00],\n",
       "        [6.65000000e+02, 4.48210000e+04, 1.20000000e+00, 4.71000000e+01,\n",
       "         4.80000000e+00],\n",
       "        [6.57302533e+02, 4.46153964e+04, 1.19427028e+00, 4.68509492e+01,\n",
       "         4.74382641e+00],\n",
       "        [5.04430453e+02, 3.88545935e+04, 1.03857627e+00, 4.50967002e+01,\n",
       "         4.51495610e+00],\n",
       "        [7.01590923e+02, 6.06253099e+04, 1.62638713e+00, 4.65327684e+01,\n",
       "         4.86185787e+00],\n",
       "        [8.47271364e+02, 2.71864395e+04, 7.27816141e-01, 3.92007581e+01,\n",
       "         4.80163985e+00],\n",
       "        [5.83121776e+02, 3.96449471e+04, 1.06173013e+00, 4.63287132e+01,\n",
       "         4.70204405e+00],\n",
       "        [8.28343523e+02, 2.80218658e+04, 7.55016176e-01, 3.97852954e+01,\n",
       "         4.79911368e+00],\n",
       "        [4.33720145e+02, 3.06562768e+04, 8.18476495e-01, 4.59154717e+01,\n",
       "         4.70269234e+00],\n",
       "        [4.77000000e+02, 3.46922100e+04, 9.29000000e-01, 4.53000000e+01,\n",
       "         4.70000000e+00],\n",
       "        [5.87047647e+02, 3.74861193e+04, 1.00292520e+00, 4.64456597e+01,\n",
       "         4.77506334e+00],\n",
       "        [5.04336898e+02, 3.86580786e+04, 1.03374565e+00, 4.51445695e+01,\n",
       "         4.51636278e+00],\n",
       "        [8.70344857e+02, 2.60197160e+04, 6.98569520e-01, 3.86120690e+01,\n",
       "         4.80613124e+00],\n",
       "        [5.02861918e+02, 3.89900572e+04, 1.04284857e+00, 4.51029704e+01,\n",
       "         4.52797517e+00],\n",
       "        [7.25732740e+02, 6.26048404e+04, 1.68622977e+00, 4.55852325e+01,\n",
       "         4.90281337e+00],\n",
       "        [5.08421042e+02, 3.90557057e+04, 1.04334410e+00, 4.50992173e+01,\n",
       "         4.51211601e+00],\n",
       "        [4.78000000e+02, 3.86893200e+04, 1.03600000e+00, 4.43000000e+01,\n",
       "         4.60000000e+00],\n",
       "        [6.04258878e+02, 3.67915685e+04, 9.80488391e-01, 4.58649312e+01,\n",
       "         4.85008200e+00]]),\n",
       " array([1000.00626081,  398.8477816 ,  792.08445342,  436.24232062,\n",
       "         579.54232206,  447.23955842,  613.24325159,  383.71187417,\n",
       "         694.63138386,  672.71625218,  643.28018583,  736.89101581,\n",
       "         675.90151839,  581.28149577,  647.02899158,  404.48866614,\n",
       "         877.2706581 ,  685.6057043 ,  419.28975914,  567.8937299 ,\n",
       "        1011.34545117,  415.40178244,  381.88826271,  763.74265701,\n",
       "         419.23757851,  613.46960485,  537.14389753,  675.53055024,\n",
       "         628.        ,  604.46053951,  626.        , 1969.02162165,\n",
       "         712.        ,  865.63487392,  675.72945784,  442.11772435,\n",
       "         614.73221804,  845.378804  , 1897.        , 1978.28077001,\n",
       "         612.17724192,  410.6497306 ,  685.78168405,  884.87909133,\n",
       "         714.8267119 ,  566.04267278,  636.        ,  781.66009007,\n",
       "         614.13251348,  674.59885487,  611.7765579 ,  395.20331453,\n",
       "         607.95879917,  606.        ,  680.15629558]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c1a9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = StandardScaler()\n",
    "x0 = scaler_x.fit_transform(x0)\n",
    "x1 = scaler_x.transform(x1)\n",
    "x2 = scaler_x.transform(x2)\n",
    "x3 = scaler_x.transform(x3)\n",
    "x_test = scaler_x.transform(x_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y0 = scaler_y.fit_transform(y0.values.reshape(-1,1))\n",
    "y1 = scaler_y.transform(y1.values.reshape(-1,1))\n",
    "y2 = scaler_y.transform(y2.values.reshape(-1,1))\n",
    "y3 = scaler_y.transform(y3.values.reshape(-1,1))\n",
    "y_test = scaler_y.transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f9704a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741d154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6aabb8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 33.69646375373835 0.9931163076556182\n",
      "Fold score (RMSE): 125.97943342380937 r2 = 0.8116183886128813\n",
      "model vs holdout : rmse 87.92684444263624 r2 = 0.9205658314406377\n",
      "training 59.792552975711644 0.972769742985276\n",
      "Fold score (RMSE): 107.66506501502897 r2 = 0.9161288744591044\n",
      "model vs holdout : rmse 73.68652979969079 r2 = 0.9471104778424589\n",
      "training 114.26718533936581 0.9005370797393417\n",
      "Fold score (RMSE): 129.2001983118896 r2 = 0.8812794641484167\n",
      "model vs holdout : rmse 134.7760402653145 r2 = 0.8071054842467552\n",
      "training 51.900831649754835 0.9771526947235474\n",
      "Fold score (RMSE): 59.629830072903495 r2 = 0.9710698109390659\n",
      "model vs holdout : rmse 72.31031589262585 r2 = 0.9465857575964619\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# Cross-Validate\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "\n",
    "fold = 0\n",
    "for i in range(1, 5):\n",
    "    K.clear_session()\n",
    "    \n",
    "    if i == 1:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x0, y0, random_state=seed)\n",
    "\n",
    "        model = keras.models.Sequential([\n",
    "        keras.layers.Dense(12, activation=\"relu\", input_shape=x_train.shape[1:]),\n",
    "\n",
    "        keras.layers.Dense(72, activation=\"relu\"),\n",
    "\n",
    "        keras.layers.Dense(1)])\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=0.01,\n",
    "                                        momentum=0.9,\n",
    "                                        nesterov=True)\n",
    "\n",
    "\n",
    "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs = 150, validation_data=(x_valid, y_valid), verbose=0)\n",
    "        pred = model.predict(x_valid)\n",
    "   \n",
    "\n",
    "        # Measure this fold's RMSE\n",
    "        print('training',\n",
    "              np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(model.predict(x_train)),\n",
    "                                                 scaler_y.inverse_transform(y_train))),\n",
    "             r2_score(scaler_y.inverse_transform(model.predict(x_train)),\n",
    "                                                 scaler_y.inverse_transform(y_train)))\n",
    "        \n",
    "        \n",
    "        score = np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(pred),\n",
    "                                                   scaler_y.inverse_transform(y_valid)))\n",
    "        r2 = r2_score(pred,y_valid)\n",
    "        print(f\"Fold score (RMSE): {score}\", 'r2 =', r2)\n",
    "        \n",
    "                        \n",
    "        r2 = r2_score(model.predict(x_test), y_test)\n",
    "        print('model vs holdout :',\n",
    "             'rmse', np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(model.predict(x_test)),\n",
    "                                                 scaler_y.inverse_transform(y_test))),\n",
    "             'r2 =', r2)\n",
    "        \n",
    "        model.save('NN_KStratified_1.h5')\n",
    "    \n",
    "    if i == 2:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x1, y1, random_state=seed)\n",
    "\n",
    "        model = keras.models.Sequential([\n",
    "        keras.layers.Dense(104, activation=\"relu\", input_shape=x_train.shape[1:]),\n",
    "\n",
    "        keras.layers.Dense(104, activation=\"sigmoid\"),\n",
    "\n",
    "        keras.layers.Dense(1)])\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=0.01,\n",
    "                                        momentum=0.9,\n",
    "                                        nesterov=True)\n",
    "\n",
    "\n",
    "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs = 150, validation_data=(x_valid, y_valid), verbose=0)\n",
    "\n",
    "        pred = model.predict(x_valid)\n",
    " \n",
    "\n",
    "        # Measure this fold's RMSE\n",
    "        print('training',\n",
    "              np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(model.predict(x_train)),\n",
    "                                                 scaler_y.inverse_transform(y_train))),\n",
    "             r2_score(scaler_y.inverse_transform(model.predict(x_train)),\n",
    "                                                 scaler_y.inverse_transform(y_train)))\n",
    "        \n",
    "        \n",
    "        score = np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(pred),\n",
    "                                                   scaler_y.inverse_transform(y_valid)))\n",
    "        r2 = r2_score(pred,y_valid)\n",
    "        print(f\"Fold score (RMSE): {score}\", 'r2 =', r2)\n",
    "        \n",
    "                        \n",
    "        r2 = r2_score(model.predict(x_test), y_test)\n",
    "        print('model vs holdout :',\n",
    "             'rmse', np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(model.predict(x_test)),\n",
    "                                                 scaler_y.inverse_transform(y_test))),\n",
    "             'r2 =', r2)\n",
    "    \n",
    "        model.save('NN_KStratified_2.h5')\n",
    "        \n",
    "    if i == 3:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x2, y2, random_state=seed)\n",
    "\n",
    "        model = keras.models.Sequential([\n",
    "        keras.layers.Dense(28, activation=\"sigmoid\", input_shape=x_train.shape[1:]),\n",
    "\n",
    "        keras.layers.Dense(72, activation=\"relu\"),\n",
    "\n",
    "        keras.layers.Dense(1)])\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=0.01,\n",
    "                                        momentum=0.9,\n",
    "                                        nesterov=True)\n",
    "\n",
    "\n",
    "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs = 150, validation_data=(x_valid, y_valid), verbose=0)\n",
    "\n",
    "        pred = model.predict(x_valid)\n",
    "\n",
    "\n",
    "        # Measure this fold's RMSE\n",
    "        print('training',\n",
    "              np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(model.predict(x_train)),\n",
    "                                                 scaler_y.inverse_transform(y_train))),\n",
    "             r2_score(scaler_y.inverse_transform(model.predict(x_train)),\n",
    "                                                 scaler_y.inverse_transform(y_train)))\n",
    "        \n",
    "        \n",
    "        score = np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(pred),\n",
    "                                                   scaler_y.inverse_transform(y_valid)))\n",
    "        r2 = r2_score(pred,y_valid)\n",
    "        print(f\"Fold score (RMSE): {score}\", 'r2 =', r2)\n",
    "        \n",
    "                        \n",
    "        r2 = r2_score(model.predict(x_test), y_test)\n",
    "        print('model vs holdout :',\n",
    "             'rmse', np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(model.predict(x_test)),\n",
    "                                                 scaler_y.inverse_transform(y_test))),\n",
    "             'r2 =', r2)\n",
    "        \n",
    "        model.save('NN_KStratified_3.h5')\n",
    "        \n",
    "    if i == 4:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x3, y3, random_state=seed)\n",
    "\n",
    "        model = keras.models.Sequential([\n",
    "        keras.layers.Dense(92, activation=\"relu\", input_shape=x_train.shape[1:]),\n",
    "\n",
    "        keras.layers.Dense(80, activation=\"sigmoid\"),\n",
    "\n",
    "        keras.layers.Dense(1)])\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=0.01,\n",
    "                                        momentum=0.9,\n",
    "                                        nesterov=True)\n",
    "\n",
    "\n",
    "        model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "\n",
    "        model.fit(x_train, y_train, epochs = 150, validation_data=(x_valid, y_valid),verbose=0)\n",
    "\n",
    "        pred = model.predict(x_valid)\n",
    "\n",
    "        # Measure this fold's RMSE\n",
    "        print('training',\n",
    "              np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(model.predict(x_train)),\n",
    "                                                 scaler_y.inverse_transform(y_train))),\n",
    "             r2_score(scaler_y.inverse_transform(model.predict(x_train)),\n",
    "                                                 scaler_y.inverse_transform(y_train)))\n",
    "        \n",
    "        \n",
    "        score = np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(pred),\n",
    "                                                   scaler_y.inverse_transform(y_valid)))\n",
    "        r2 = r2_score(pred,y_valid)\n",
    "        print(f\"Fold score (RMSE): {score}\", 'r2 =', r2)\n",
    "        \n",
    "                        \n",
    "        r2 = r2_score(model.predict(x_test), y_test)\n",
    "        print('model vs holdout :',\n",
    "             'rmse', np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(model.predict(x_test)),\n",
    "                                                 scaler_y.inverse_transform(y_test))),\n",
    "             'r2 =', r2)\n",
    "        \n",
    "        model.save('NN_KStratified_4.h5')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0867d43",
   "metadata": {},
   "source": [
    "# test ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2968e3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 43.995912276893755 0.9884657094065201\n",
      "Fold score (RMSE): 66.23692323505773 r2 = 0.9425294311208653\n",
      "model vs holdout : rmse 80.87703258317016 r2 = 0.9527215899822977\n",
      "training 46.36569618303712 0.9848127538202387\n",
      "Fold score (RMSE): 65.36824610823594 r2 = 0.967651116844121\n",
      "model vs holdout : rmse 80.87703258317016 r2 = 0.9527215899822977\n",
      "training 49.20228424385366 0.9844538867457194\n",
      "Fold score (RMSE): 66.35955670605 r2 = 0.97509934378731\n",
      "model vs holdout : rmse 80.87703258317016 r2 = 0.9527215899822977\n",
      "training 39.72310945294477 0.9877513576353428\n",
      "Fold score (RMSE): 36.40077176920253 r2 = 0.990182545025853\n",
      "model vs holdout : rmse 80.87703258317016 r2 = 0.9527215899822977\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "ensemble_model = keras.models.load_model('NN_ensemble_new_layer.h5')\n",
    "\n",
    "# Cross-Validate\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "\n",
    "fold = 0\n",
    "for i in range(1, 5):\n",
    "    K.clear_session()\n",
    "    \n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(eval(f\"x{i-1}\"), eval(f\"y{i-1}\") , random_state=seed)\n",
    "    \n",
    "\n",
    "    # Measure this fold's RMSE\n",
    "    print('training',\n",
    "          np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(ensemble_model.predict(x_train)),\n",
    "                                             scaler_y.inverse_transform(y_train))),\n",
    "         r2_score(ensemble_model.predict(x_train),\n",
    "                                             y_train))\n",
    "\n",
    "\n",
    "    score = np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(ensemble_model.predict(x_valid)),\n",
    "                                               scaler_y.inverse_transform(y_valid)))\n",
    "    r2 = r2_score(ensemble_model.predict(x_valid),y_valid)\n",
    "    print(f\"Fold score (RMSE): {score}\", 'r2 =', r2)\n",
    "\n",
    "\n",
    "    r2 = r2_score(ensemble_model.predict(x_test), y_test)\n",
    "    print('model vs holdout :',\n",
    "             'rmse', np.sqrt(metrics.mean_squared_error(scaler_y.inverse_transform(model.predict(x_test)),\n",
    "                                                 scaler_y.inverse_transform(y_test))),\n",
    "             'r2 =', r2) \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e17f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
